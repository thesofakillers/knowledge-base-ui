---
date: 2020-10-09 14:22:09
title: Operator Overloading for forward-mode Autodiff 
id: 2020-10-09t14-22-09z
---

[Dual Numbers](./2020-10-09t20-35-29z.md) seem almost specifically designed for
differentiation, if we think of the auxiliary term $\epsilon$ as some
infinitesimally small but positive quantity whose higher orders can be
neglected, as the notation of $\epsilon^2 = 0$ suggests.

In investigating dual numbers, we find that 

$$
(a+b\epsilon)^2 = a^2 + 2ab\epsilon.
$$

What this tells us is that if we consider the function $f(x) = x^2$, then
applying it to a dual number of the form $a + b \epsilon$ will give us 

$$
f(a + b\epsilon) = f(a) + f'(a) b \epsilon.
$$

In other words, taking the square of a dual number will give us a result
encoding the same function and its derivative evaluated at the real part of
the dual number.

The binomial theorem $(a+b\epsilon)^n = a^n + na^{n-1}b\epsilon$ reassures us
that this in fact generalizes to any function. We may therefore extend the
definition of a real function $f(x)$ to dual numbers $a + b\epsilon$ such that 

$$
f(a + b\epsilon) = f(a) + f'(a) b \epsilon.
$$

This of course extends to the product and chain rule. For a given function
then, we can evaluate it and its derivative at a point $x = a$ by building its
computational graph and substituting the dual number $a + \epsilon$ for $x$.
Since we are moving through the graph in the order in which it is built, i.e.
from the inside out, this is nothing more than
[forward-mode autodiff](./2020-10-12t20-09-18z.md). 

This mechanism is at the base of operator overloading. This consists in
defining a new data type that models dual numbers, and then extending
(overloading) our primitive operators ($+, -, \times, \div, \log, \cos, \sin,$
etc.) to support this new data type.

Our gradient function will then simply take our input variables and convert
them to their dual number equivalents before evaluating the original function,
obtaining both the output of the function itself and of its derivative.
