---
date: 2020-09-23 14:52:52
title: Cross-Validation
id: 2020-09-23t14-52-52z
---

In statistics and machine learning, Cross-validation is the process of
_estimating_ how well a trained model generalizes by assessing its performance
on an unseen set of data.

One often makes use of cross-validation to aid in model choice. Typically, the
training dataset is tackled using several different models, which are then
compared using cross-validation on the (appropriately named) validation dataset.
The best model is then chosen to be evaluated against the test dataset.

A common approach to cross-validation is k-fold cross validation, in which we
define k different splits of training and validation data, assessing the model
on each of those splits and combining the outcome.

- [CV Wikipedia article](<https://en.wikipedia.org/wiki/Cross-validation_(statistics)>)
- [Train, Validation, Test datasets Wikipedia Article](https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets)
- [Useful K-fold discussion on stackexchange](https://stats.stackexchange.com/questions/52274/how-to-choose-a-predictive-model-after-k-fold-cross-validation)
- [A tutorial on k-fold cv](https://machinelearningmastery.com/k-fold-cross-validation/)
- [Rob Hyndman's CV article](https://robjhyndman.com/hyndsight/crossvalidation/)
